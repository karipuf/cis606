{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "california=california_housing.fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=scale(california['data'])\n",
    "y=california['target']\n",
    "\n",
    "df=pd.DataFrame(x,columns=california['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting into train and test sets\n",
    "\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest regressor\n",
    "\n",
    "* Benchmark system\n",
    "* RF generally gives great performance for problems like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14448, 8)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf=RandomForestRegressor(n_estimators=100).fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26596963096238341"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE Error\n",
    "np.mean((rf.predict(xtest)-ytest)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Deep\" Neural Network\n",
    "\n",
    "* Two hidden layers\n",
    "* Investigate the effect of different params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nhidden1=250\n",
    "nhidden2=200\n",
    "n_iter=1000\n",
    "activation=tf.nn.relu\n",
    "#activation=tf.nn.sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateDN(x,dropKeep,numUnits):\n",
    "   \n",
    "    # Setting things up\n",
    "    nIn=int(x.shape[1])\n",
    "    y=x\n",
    "    l2=0\n",
    "    \n",
    "    for layer in range(len(numUnits)):\n",
    "        \n",
    "        w=tf.get_variable(\"w\"+str(layer),initializer=tf.glorot_normal_initializer(),shape=(nIn,numUnits[layer]))\n",
    "        b=tf.get_variable('b'+str(layer),initializer=tf.zeros_initializer(),shape=(numUnits[layer]))\n",
    "        a=tf.add(tf.matmul(y,w),b,name=\"a\"+str(layer))\n",
    "        if layer==len(numUnits)-1:\n",
    "            y=a\n",
    "        else:\n",
    "            y=tf.nn.relu(a)\n",
    "            y=tf.nn.dropout(y,keep_prob=dropKeep)\n",
    "    \n",
    "        l2+=tf.reduce_sum(w**2)\n",
    "    \n",
    "        # Prepping for next layer, if present\n",
    "        nIn=numUnits[layer]\n",
    "        \n",
    "    return y,l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_iter=1500\n",
    "\n",
    "nx=tf.placeholder(tf.float32,(None,8))\n",
    "dk=tf.placeholder(tf.float32,())\n",
    "target=tf.placeholder(tf.float32,(None,1))\n",
    "\n",
    "ny,l2=CreateDN(nx,dk,[256,160,64,1])\n",
    "testloss=tf.losses.mean_squared_error(ny,target)\n",
    "loss=testloss+l2*.0\n",
    "opt=tf.train.AdamOptimizer(learning_rate=.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter #0, training loss is 5.3795, test loss is 2.70036\n",
      "iter #50, training loss is 0.517459, test loss is 0.395986\n",
      "iter #100, training loss is 0.446613, test loss is 0.338995\n",
      "iter #150, training loss is 0.409337, test loss is 0.31889\n",
      "iter #200, training loss is 0.397643, test loss is 0.310944\n",
      "iter #250, training loss is 0.369275, test loss is 0.311057\n",
      "iter #300, training loss is 0.362997, test loss is 0.291713\n",
      "iter #350, training loss is 0.346487, test loss is 0.292763\n",
      "iter #400, training loss is 0.323148, test loss is 0.278784\n",
      "iter #450, training loss is 0.323492, test loss is 0.294626\n",
      "iter #500, training loss is 0.312681, test loss is 0.28051\n",
      "iter #550, training loss is 0.309541, test loss is 0.284968\n",
      "iter #600, training loss is 0.298976, test loss is 0.282553\n",
      "iter #650, training loss is 0.289716, test loss is 0.27268\n",
      "iter #700, training loss is 0.293659, test loss is 0.281345\n",
      "iter #750, training loss is 0.287884, test loss is 0.279432\n",
      "iter #800, training loss is 0.283981, test loss is 0.274719\n",
      "iter #850, training loss is 0.279501, test loss is 0.268107\n",
      "iter #900, training loss is 0.277939, test loss is 0.273137\n",
      "iter #950, training loss is 0.266957, test loss is 0.269777\n",
      "iter #1000, training loss is 0.265105, test loss is 0.267112\n",
      "iter #1050, training loss is 0.268147, test loss is 0.26633\n",
      "iter #1100, training loss is 0.267139, test loss is 0.269368\n",
      "iter #1150, training loss is 0.261157, test loss is 0.265014\n",
      "iter #1200, training loss is 0.262607, test loss is 0.263146\n",
      "iter #1250, training loss is 0.263831, test loss is 0.262585\n",
      "iter #1300, training loss is 0.260237, test loss is 0.263697\n",
      "iter #1350, training loss is 0.252303, test loss is 0.262229\n",
      "iter #1400, training loss is 0.257006, test loss is 0.262078\n",
      "iter #1450, training loss is 0.252658, test loss is 0.262793\n"
     ]
    }
   ],
   "source": [
    "try: sess.close()\n",
    "except: pass\n",
    "\n",
    "sess=tf.Session()\n",
    "    \n",
    "writer = tf.summary.FileWriter(\"/home/wlwoon/tmp/day14log\", sess.graph)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "for count in range(n_iter):\n",
    "        \n",
    "    _,tloss=sess.run([opt,loss],feed_dict={dk:.6,nx:xtrain,target:ytrain.reshape((-1,1))})\n",
    "      \n",
    "    if count % 50 ==0:\n",
    "        test_loss=sess.run(testloss,feed_dict={dk:1.0,nx:xtest,target:ytest.reshape((-1,1))})\n",
    "        print(\"iter #\"+str(count)+\", training loss is \"+str(tloss)+\", test loss is \"+str(test_loss))\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.38776541],\n",
       "       [ 3.07113528],\n",
       "       [ 2.02339411],\n",
       "       [ 2.4841907 ],\n",
       "       [ 1.08343816]], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(ny,feed_dict={dk:1,nx:xtest[:5,:]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.02065714,  0.99876618,  0.84249565,  0.74652804,  1.00117305,\n",
       "        1.54552267,  1.00237812,  0.99950791])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ytest**2)\n",
    "np.std(xtest,axis=0)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
